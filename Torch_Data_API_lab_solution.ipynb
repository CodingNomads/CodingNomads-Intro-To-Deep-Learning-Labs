{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Torch_Data_API_lab_solution.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObbiDj4wZpXx4uRoDDBB+m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0KAQ3YYS82eM"},"source":["# Torch Data API Lab\n","\n","In this lab, you will create your own dataset and dataloader.\n","This is a key part of the ML workflow with torch.\n","You'll have two chances to practice creating datasets and dataloaders with different types of data.\n","Be prepared to do some external research on things like `glob` syntax, `pathlib`, and working with `PIL.Image` objects.\n","\n","Make sure to take time to inspect and learn about the objects you're working with as you're working through these exercises."]},{"cell_type":"markdown","metadata":{"id":"h8ss3xOf9OOL"},"source":["## Setup\n","\n","In the cell below, import the `Dataset` and `DataLoader` classes from `torch`.\n","It's useful to remember where these are, since you'll be importing them a lot!"]},{"cell_type":"code","metadata":{"id":"ywQWfIe89YwH","executionInfo":{"status":"ok","timestamp":1633285428290,"user_tz":420,"elapsed":840,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Your work here\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQ7U1afH9kJz"},"source":["## Wine Dataset\n","\n","This section contains no work. \n","Run this section to lode the wine dataset into a `pd.DataFrame`.\n","In the first section of this lab, you'll be working with this dataframe to create datasets and dataloaders."]},{"cell_type":"code","metadata":{"id":"YKrgw8fx9nfg","executionInfo":{"status":"ok","timestamp":1633285428292,"user_tz":420,"elapsed":5,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["import requests\n","import pandas as pd\n","import numpy as np\n","import torch"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjL1QLc79-YW","executionInfo":{"status":"ok","timestamp":1633285429652,"user_tz":420,"elapsed":1364,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}},"outputId":"d8fe2538-c2d2-41cb-e1f8-0c5870b574e9"},"source":["URLS = [\n","    'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv',\n","    'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv',\n","    'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names'\n","]\n","for url in URLS:\n","    !wget {url}"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-03 18:23:48--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n","Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n","Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84199 (82K) [application/x-httpd-php]\n","Saving to: ‘winequality-red.csv’\n","\n","winequality-red.csv 100%[===================>]  82.23K  --.-KB/s    in 0.1s    \n","\n","2021-10-03 18:23:48 (825 KB/s) - ‘winequality-red.csv’ saved [84199/84199]\n","\n","--2021-10-03 18:23:48--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n","Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n","Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 264426 (258K) [application/x-httpd-php]\n","Saving to: ‘winequality-white.csv’\n","\n","winequality-white.c 100%[===================>] 258.23K  1.25MB/s    in 0.2s    \n","\n","2021-10-03 18:23:49 (1.25 MB/s) - ‘winequality-white.csv’ saved [264426/264426]\n","\n","--2021-10-03 18:23:49--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names\n","Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n","Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3305 (3.2K) [application/x-httpd-php]\n","Saving to: ‘winequality.names’\n","\n","winequality.names   100%[===================>]   3.23K  --.-KB/s    in 0s      \n","\n","2021-10-03 18:23:49 (86.2 MB/s) - ‘winequality.names’ saved [3305/3305]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"llaQkWev-BNC","executionInfo":{"status":"ok","timestamp":1633285429653,"user_tz":420,"elapsed":4,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["red = pd.read_csv('winequality-red.csv', delimiter=';')\n","red['is_red'] = 1\n","white = pd.read_csv('winequality-white.csv', delimiter=';')\n","white['is_red'] = 0\n","wine = red.append(white).reset_index(drop=True)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yYgQg045-peK"},"source":["### Split data into training and validaiton sets.\n","\n","Question: \n","What are train and validation datasets used for in machine learning?\n","\n","Answer:\n","* Train: the train set is used to find optimal parameters for your model.\n","* Validation: the validation dataset is used to detect overfitting as you train and tune hyperparameters."]},{"cell_type":"code","metadata":{"id":"Xfb-QVep_fjm","executionInfo":{"status":"ok","timestamp":1633285430167,"user_tz":420,"elapsed":517,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEfM4_reAoHX","executionInfo":{"status":"ok","timestamp":1633285430167,"user_tz":420,"elapsed":12,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["train, valid = train_test_split(wine, random_state=42, stratify=wine.is_red)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bk5tXZmEA0Mq"},"source":["### Create a class for you Dataset\n","\n","The only argument to the dataset should be a `pd.DataFrame`.\n","The `WineDataset` object should implement the following methods:\n","* a `__len__` method, that returns the number of rows in the dataset\n","* a `__getitem__` method, that returns an (X, y) tuple at an index in the dataset.\n","\n","In this case, your X value shoudl be values in the DataFrame, and the y value should be the quality rating."]},{"cell_type":"code","metadata":{"id":"ECmNOVqSBp03","executionInfo":{"status":"ok","timestamp":1633285430169,"user_tz":420,"elapsed":8,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["class WineDataset(Dataset):\n","    def __init__(self, df):\n","        super().__init__()\n","        self.df = df\n","        self.x_cols = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n","            'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n","            'pH', 'sulphates', 'alcohol']\n","        self.y_col = 'quality'\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        return self.df[self.x_cols].iloc[idx].values, self.df[self.y_col].iloc[idx]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwLrHq3vChZR","executionInfo":{"status":"ok","timestamp":1633285430170,"user_tz":420,"elapsed":8,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["train_ds = WineDataset(train)\n","valid_ds = WineDataset(valid)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"vMXGQJMsCl3X","executionInfo":{"status":"ok","timestamp":1633285430170,"user_tz":420,"elapsed":8,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Sanity checks\n","x, y = train_ds[0]\n","assert isinstance(x, (np.ndarray, torch.Tensor)), \"\"\"\n","x should be an array or tensor.\n","\"\"\"\n","assert isinstance(y, (int, float, torch.Tensor, np.number)), \"\"\"\n","y should be some numeric type.\n","\"\"\""],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvbxsw2tP_Ji"},"source":["Take a look at `x` and `y` to make sure they are in line with your expectations."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFrhR17iKPWL","executionInfo":{"status":"ok","timestamp":1633285430338,"user_tz":420,"elapsed":13,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}},"outputId":"8fe2f0ef-cf5a-4c99-e0f8-f8b95cb75a25"},"source":["x"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([7.4000e+00, 2.7000e-01, 3.1000e-01, 2.4000e+00, 1.4000e-02,\n","       1.5000e+01, 1.4300e+02, 9.9094e-01, 3.0300e+00, 6.5000e-01,\n","       1.2000e+01])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhrQLbMGKQub","executionInfo":{"status":"ok","timestamp":1633285430338,"user_tz":420,"elapsed":9,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}},"outputId":"10befbf2-01f2-4f12-9791-731212e02a72"},"source":["y"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"R0RKQY93Llxr"},"source":["## Create your train and validation DataLoaders from your datasets.\n","\n","By now, you should have train and validation datasets instantiated."]},{"cell_type":"code","metadata":{"id":"iDUY8Al-Cxoi","executionInfo":{"status":"ok","timestamp":1633285430339,"user_tz":420,"elapsed":7,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["train_dl = DataLoader(train_ds, batch_size=16)\n","valid_dl = DataLoader(valid_ds, batch_size=16)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bo8d-eyJJcQx","executionInfo":{"status":"ok","timestamp":1633285430339,"user_tz":420,"elapsed":6,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Sanity checks\n","for x, y in train_dl:\n","    break\n","assert isinstance(x, torch.Tensor)\n","assert isinstance(y, torch.Tensor)\n","assert x.shape[0] == y.shape[0]"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X3yYwiA1IxNl"},"source":["## More practice with images: Dogs!"]},{"cell_type":"code","metadata":{"id":"AcjWLrroJsF8","executionInfo":{"status":"ok","timestamp":1633285433858,"user_tz":420,"elapsed":3525,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["!pip install -Uqq fastai"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5QGTtyMIbkkX"},"source":["### Download the dataset"]},{"cell_type":"code","metadata":{"id":"X4KdzxLNIZQl","executionInfo":{"status":"ok","timestamp":1633285434195,"user_tz":420,"elapsed":340,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["from fastai.vision.all import untar_data, URLs, Path\n","from PIL import Image\n","import typing"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"NyrCElR4IiCk","executionInfo":{"status":"ok","timestamp":1633285434196,"user_tz":420,"elapsed":12,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["path = untar_data(URLs.IMAGEWOOF_320)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWD7GHeeKgR2","executionInfo":{"status":"ok","timestamp":1633285434196,"user_tz":420,"elapsed":10,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}},"outputId":"03b64af7-9506-4ac1-8686-5fa863bd69f9"},"source":["list(path.ls())"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Path('/root/.fastai/data/imagewoof2-320/noisy_imagewoof.csv'),\n"," Path('/root/.fastai/data/imagewoof2-320/val'),\n"," Path('/root/.fastai/data/imagewoof2-320/train')]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"9aUxplmTNPPo","executionInfo":{"status":"ok","timestamp":1633285434197,"user_tz":420,"elapsed":6,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["one_image_path = (path/'train/n02099601').ls()[0]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JbNgzUIOo2N","executionInfo":{"status":"ok","timestamp":1633285434197,"user_tz":420,"elapsed":6,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["train_path = path/'train'\n","valid_path = path/'val'"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nBGyXKCVbofN"},"source":["### Create some utility functions & objects we'll use later."]},{"cell_type":"code","metadata":{"id":"RPFFGVgkOjxn","executionInfo":{"status":"ok","timestamp":1633285434197,"user_tz":420,"elapsed":5,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Create a function that lists all the image files in a path.\n","# This function shuld return a list of image file paths.\n","# HINT: Use path.glob with glob syntax \n","# https://docs.python.org/3/library/glob.html\n","def list_image_files(path:Path):\n","    return list(path.glob('**/*.JPEG'))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"niZGJT0XS-Vo","executionInfo":{"status":"ok","timestamp":1633285434443,"user_tz":420,"elapsed":251,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Make sure list_image_files returns only .JPEG files\n","assert set(i.suffix for i in list_image_files(train_path)) == {'.JPEG'}"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"J-A6DM-yMGrG","executionInfo":{"status":"ok","timestamp":1633285434444,"user_tz":420,"elapsed":3,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Create a function that opens an image from a path\n","# This function should return a PIL.Image\n","def open_image(path):\n","    return Image.open(path)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"OijRLu8mNNJl","executionInfo":{"status":"ok","timestamp":1633285434444,"user_tz":420,"elapsed":3,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Sanity check: open_image returns a PIL.Image\n","img = open_image(one_image_path)\n","assert isinstance(img, Image.Image)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsFSfKM6Maps","executionInfo":{"status":"ok","timestamp":1633285434722,"user_tz":420,"elapsed":281,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Create a function to label the image by the path. \n","# The label in this case is the parent directory.\n","def label_from_image_path(path):\n","    return path.parent.name"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"niJv_yr_NI_3","executionInfo":{"status":"ok","timestamp":1633285434723,"user_tz":420,"elapsed":11,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Sanity check: function correctly labels a single image\n","assert label_from_image_path(one_image_path) == 'n02099601'"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Q7Gg_3cOCNx","executionInfo":{"status":"ok","timestamp":1633285434723,"user_tz":420,"elapsed":10,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Create a function that resizes a PIL Image to (244, 244)\n","# We resize images so they're all the same shape when\n","# we put them into a batch. We'll learn about more\n","# sophisticated ways to do this when we cover CNNs.\n","def resize_image(img):\n","    return img.resize((244, 244))"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-emtBjXOMk5","executionInfo":{"status":"ok","timestamp":1633286727209,"user_tz":420,"elapsed":149,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Sanity check: image resized to (244, 244)\n","img = open_image(one_image_path)\n","assert not img.shape == (244, 244)\n","assert resize_image(img).shape == (244, 244)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_WKEP2KSYv0","executionInfo":{"status":"ok","timestamp":1633285434724,"user_tz":420,"elapsed":10,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}},"outputId":"34fd89da-0ec7-4982-9050-70b1162e4794"},"source":["# Find all the unique labels in the train set.\n","# We will use these to encode our labels in our Dataset.\n","# The labels variable should be a list of all the classes \n","# (for example, 'n02115641')\n","labels = list(set(label_from_image_path(path) for path in list_image_files(train_path)))\n","labels, len(labels)"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['n02115641',\n","  'n02105641',\n","  'n02088364',\n","  'n02096294',\n","  'n02086240',\n","  'n02087394',\n","  'n02089973',\n","  'n02099601',\n","  'n02093754',\n","  'n02111889'],\n"," 10)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"ntQlnEunfo7l","executionInfo":{"status":"ok","timestamp":1633287067725,"user_tz":420,"elapsed":143,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Label sanity checks\n","assert isinstance(labels, list)\n","assert len(labels) == 10"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Htu9HddPbzIB"},"source":["### Create your DogDataset class.\n","\n","This dataset should be instantiated with a `Path` object for the train or valid DS.\n","The `__getitem__` method should return a tuple of `(PIL.Image.Image, int)`, where the int is the index of the label in the `labels` object we defined above."]},{"cell_type":"code","metadata":{"id":"TzMM-laKOely","executionInfo":{"status":"ok","timestamp":1633285434725,"user_tz":420,"elapsed":8,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["class DogDataset(Dataset):\n","    def __init__(self, path):\n","        self.path = Path(path)\n","        self.files = list_image_files(self.path)\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, idx):\n","        return open_image(self.files[idx]), labels.index(label_from_image_path(self.files[idx]))"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"wx0xjofkP4Ta","executionInfo":{"status":"ok","timestamp":1633285434725,"user_tz":420,"elapsed":7,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["train_ds = DogDataset(train_path)\n","valid_ds = DogDataset(valid_path)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8m5ilCxP63U","executionInfo":{"status":"ok","timestamp":1633286628032,"user_tz":420,"elapsed":127,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Sanity checks for the DogDataset\n","x, y = train_ds[0]\n","assert isinstance(x, Image.Image)\n","assert isinstance(y, int)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HX-wCkAQbrY","executionInfo":{"status":"ok","timestamp":1633285434726,"user_tz":420,"elapsed":7,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Create a collate_fn that resizes returns a batch of images and labels as tensors.\n","# The function should resize all the images to (244, 244) and\n","# normalize images between 0 and 1 by dividing all values by 255\n","def collate_fn(batch):\n","    imgs, labels = tuple(zip(*batch))\n","    imgs = [np.array(resize_image(img)) for img in imgs]\n","    imgs = torch.tensor(imgs) / 255.\n","    labels = torch.tensor(labels)\n","    return imgs, labels"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dcs3TkdHRpXJ","executionInfo":{"status":"ok","timestamp":1633285435573,"user_tz":420,"elapsed":854,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Sanity checks for collate function\n","one_batch = [train_ds[i] for i in range(8)]\n","x, y = collate_fn(one_batch)\n","assert isinstance(x, torch.Tensor)\n","assert x.max() <= 1\n","assert x.ndim == 4\n","assert isinstance(y, torch.Tensor)\n","assert x.shape[0] == y.shape[0]"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QUZbQ_NTfPUW"},"source":["### Create your train and validation DataLoaders\n","\n","At this point, you should have everything you need to create your `DataLoader` objects for your train and validation datasets.\n","Your `DogDataset` object should load objects from disk into memory, and your `collate_fn` should be able to take a batch of these raw objects and convert them into tensors."]},{"cell_type":"code","metadata":{"id":"oCO0Xdx7UopA","executionInfo":{"status":"ok","timestamp":1633285435574,"user_tz":420,"elapsed":4,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Create a train and valid DataLoader where batch_size = 16.\n","# Don't forget to pass your collate_fn!\n","train_dl = DataLoader(train_ds, batch_size=16, collate_fn=collate_fn)\n","valid_dl = DataLoader(valid_ds, batch_size=16, collate_fn=collate_fn)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"9rG46rcMXyhM","executionInfo":{"status":"ok","timestamp":1633285437047,"user_tz":420,"elapsed":1476,"user":{"displayName":"Mike Frantz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64","userId":"08482506601269125384"}}},"source":["# Sanity checks for the dataloader\n","for x, y in train_dl:\n","    break\n","assert isinstance(x, torch.Tensor)\n","assert x.max() <= 1\n","assert x.ndim == 4\n","assert isinstance(y, torch.Tensor)\n","assert x.shape[0] == y.shape[0]"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ClpYKsvmX0P_"},"source":["## Review\n","\n","In this lab, we created two different dataloaders that return batches of data we could use to train an ML model.\n","One works with in-memory data in the form of a `pd.DataFrame`, and the other works with out-of-memory data in the form of image files.\n","We'll get plenty more practice with other methods of creating datasets and dataloaders throught the course!"]},{"cell_type":"code","metadata":{"id":"jl7qkdn8hMh7"},"source":[""],"execution_count":null,"outputs":[]}]}