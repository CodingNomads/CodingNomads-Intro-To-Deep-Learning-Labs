{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBDfgfJY6X2F"
   },
   "outputs": [],
   "source": [
    "!pip install torchmetrics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6FyQ11IDHTG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1623902473465,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "aVnQSeXZahJI",
    "outputId": "bb023d87-7889-42dd-8623-04dd1f28ce29"
   },
   "outputs": [],
   "source": [
    "# Maybe delete this. Not sure if I want to get into GPUs yet, that should be a separate lesson.\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu:0'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvKaTo03-UQ-"
   },
   "outputs": [],
   "source": [
    "# Load the train and validation data\n",
    "mnist_train = pd.read_csv('sample_data/mnist_train_small.csv', header=None)\n",
    "mnist_valid = pd.read_csv('sample_data/mnist_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1623902477503,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "zGuzgVZD9Zg9",
    "outputId": "637d40ec-2e10-4ba8-c7e9-b463971e36c2"
   },
   "outputs": [],
   "source": [
    "# Take a look at the data.\n",
    "# It looks like the first column is the label,\n",
    "# And columns 1 - 785 are pixels.\n",
    "print(mnist_train.shape)\n",
    "mnist_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1623902477916,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "K9KSy4IBJsHN",
    "outputId": "957a50a6-02dd-4406-8e95-f112c9e6af76"
   },
   "outputs": [],
   "source": [
    "# What's the distribuiont of labels in the train set?\n",
    "mnist_train[0].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1623902478134,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "uJHfKi8cJ985",
    "outputId": "aad3c025-44f9-447d-e715-78fa3faa0126"
   },
   "outputs": [],
   "source": [
    "# What's the distribuiont of labels in the validation set?\n",
    "mnist_train[0].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIYGoVRMx91l"
   },
   "outputs": [],
   "source": [
    "def show_number(row, ax=None):\n",
    "    \"\"\"\n",
    "    This function shows a row as an image, and titles it with the label.\n",
    "    \n",
    "    Options:\n",
    "    * row: a row from either of the mnist_train or mnist_valid dataframes.\n",
    "    * ax: if not None, will plot the digit on the provided ax.\n",
    "        Otherwise, this function should create a figure and \n",
    "    \"\"\"\n",
    "    return_fig = ax == None\n",
    "    target, values = row.values[0], row.values[1:].reshape(28, 28)\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.imshow(values, cmap='gray_r')\n",
    "    ax.set_title(target)\n",
    "    \n",
    "    plt.close()\n",
    "    if return_fig:\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1623902478334,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "pjwuD3W7Ay7j",
    "outputId": "c37ff2ef-593d-4eac-f826-546eb34c1d13"
   },
   "outputs": [],
   "source": [
    "show_number(mnist_train.sample(1).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbhVnnjW-wHK"
   },
   "outputs": [],
   "source": [
    "def show_many(n_rows=3, n_cols=3):\n",
    "    \"\"\"\n",
    "    This function shows a number of images at a time, by default 9.\n",
    "    It takes a random sample of (n_rows * n_cols) of the training data to show.\n",
    "    \"\"\"\n",
    "    # Sample the training data\n",
    "    train_df_sample = mnist_train.sample(n_rows * n_cols)\n",
    "    # Create the figure\n",
    "    fig = plt.figure(figsize=(4*n_cols, 4*n_rows))\n",
    "    # For each row in the sample, plot the number\n",
    "    for i, (_, row) in enumerate(train_df_sample.iterrows()):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, 1+i)\n",
    "        show_number(row, ax)\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "executionInfo": {
     "elapsed": 1556,
     "status": "ok",
     "timestamp": 1623902479881,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "QAmtLzYP07er",
    "outputId": "1dabad81-8b48-400c-ab77-3a07103ce2c1"
   },
   "outputs": [],
   "source": [
    "show_many()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1623902479886,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "0CTuMZo532Kn",
    "outputId": "22a12b05-e26a-470b-e6e0-6671de8bb714"
   },
   "outputs": [],
   "source": [
    "# What are the min and max values of the data?\n",
    "mnist_train.loc[:, 1:].values.max(), \\\n",
    "mnist_train.loc[:, 1:].values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1623902479887,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "CYRHdIphKc2V",
    "outputId": "cf6d1376-a6e1-46ef-87b0-3690cfd0a5cd"
   },
   "outputs": [],
   "source": [
    "plt.hist(mnist_train.loc[:, 1:].values.ravel())\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.xlabel('Value')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1A1BoEqQ3_YP"
   },
   "outputs": [],
   "source": [
    "# Let's scale all the data between 0 and 1.\n",
    "mnist_train_scaled = mnist_train.copy()\n",
    "mnist_train_scaled.loc[:, 1:] /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKUlrbHx4T3x"
   },
   "outputs": [],
   "source": [
    "mnist_valid_scaled = mnist_valid.copy()\n",
    "mnist_valid_scaled.loc[:, 1:] /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1623902496320,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "Pk6BerUY4Rrg",
    "outputId": "59288140-071a-433b-bf57-cb4a6e4fcec4"
   },
   "outputs": [],
   "source": [
    "mnist_train_scaled.loc[:, 1:].values.max(), \\\n",
    "mnist_train_scaled.loc[:, 1:].values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPtwZS5A2j9j"
   },
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vH_VYzCz4irc"
   },
   "outputs": [],
   "source": [
    "# Create datasets from the dataframes\n",
    "train_ds = MnistDataset(mnist_train_scaled)\n",
    "valid_ds = MnistDataset(mnist_valid_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "du9MTd3B0_gX"
   },
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "_x, _y = train_ds[0]\n",
    "assert _x.shape[0] == mnist_train_scaled.shape[1] - 1\n",
    "assert _y == mnist_train_scaled.loc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xisQA_Wfzl6G"
   },
   "outputs": [],
   "source": [
    "#@markdown Answer: `MnistDataset`\n",
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y = torch.tensor(self.df.loc[idx, 0])\n",
    "        x = torch.FloatTensor(self.df.loc[idx, 1:].values)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VO4G7cPA4zQd"
   },
   "outputs": [],
   "source": [
    "# Create dataloaders from the datasets.\n",
    "# During the training phase, we need to keep both the activations \n",
    "# and the gradients in memory. However during the validation phase,\n",
    "# we don't have to store gradients so we can double the batch size!\n",
    "\n",
    "train_dl = None\n",
    "valid_dl = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "cEugMBvk2uKr"
   },
   "outputs": [],
   "source": [
    "#@markdown Answer: `train_dl` and `valid_dl`\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jZFug0E3JcB"
   },
   "outputs": [],
   "source": [
    "def linear(in_features, out_features, dropout=0.2):\n",
    "    \"\"\"\n",
    "    Returns an nn.Sequential module that we want to repeat a lot.\n",
    "    The module contains a linear layer, ReLU activation, BatchNorm, and dropout.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXUhyeGN4nU-"
   },
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "assert len(linear(1,1)) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "uBIXsIG84gQX"
   },
   "outputs": [],
   "source": [
    "#@markdown Answer: `linear`\n",
    "def linear(in_features, out_features, dropout=0.2, batch_norm=True):\n",
    "    \"\"\"\n",
    "    Returns an nn.Sequential module that we want to repeat a lot.\n",
    "    The module contains a linear layer, ReLU activation, BatchNorm, and dropout.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(out_features),\n",
    "        nn.Dropout(dropout),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukf-1HXu2CyR"
   },
   "outputs": [],
   "source": [
    "# Define some parameters for the model\n",
    "N_INPUT_FEATURES = 28*28\n",
    "N_HIDDEN_LAYERS = 2\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFTpRLFg5ela"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    None\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0vDVxKo2jij"
   },
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "assert len(model) == N_HIDDEN_LAYERS + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i32PHOveL5E8"
   },
   "outputs": [],
   "source": [
    "# Another sanity check: our model should be able to operate on a batch of data.\n",
    "for x_b, y_b in train_dl:\n",
    "    break\n",
    "model(x_b.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "kjS7AzAp7bNK"
   },
   "outputs": [],
   "source": [
    "#@markdown Answer: `model`\n",
    "model = nn.Sequential(\n",
    "    linear(N_INPUT_FEATURES, HIDDEN_DIM),\n",
    "    *tuple(linear(HIDDEN_DIM, HIDDEN_DIM) for _ in range(N_HIDDEN_LAYERS)),\n",
    "    nn.Linear(HIDDEN_DIM, OUTPUT_DIM)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgqtKpau5RjN"
   },
   "outputs": [],
   "source": [
    "loss_func = ...\n",
    "opt = ...\n",
    "metric = torchmetrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "-EabyhhLEN3C"
   },
   "outputs": [],
   "source": [
    "#@markdown Answer: `loss_func`, `opt`, and `metric`\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters()) # This can totally be a different optimizer, up to you!\n",
    "metric = torchmetrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xOfbQ4T-L3S"
   },
   "outputs": [],
   "source": [
    "def train_step(x_b, y_b):\n",
    "    # Send x_b and y_b to the GPU, if available\n",
    "    x_b = ...\n",
    "    y_b = ...\n",
    "    # Generate yhat\n",
    "    yhat = ...\n",
    "    # Calculate the loss\n",
    "    loss = ...\n",
    "    # Calculate gradients\n",
    "\n",
    "    # Perform your update and zero out your gradients\n",
    "    opt.\n",
    "    opt.\n",
    "\n",
    "    # Update your accuracy metric. We'll give you this one!\n",
    "    batch_acc = metric(yhat.cpu().softmax(axis=1), y_b.cpu())\n",
    "\n",
    "    # Return the loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "KWATaYOsDwuc"
   },
   "outputs": [],
   "source": [
    "#@markdown Answer: `train_step`\n",
    "def train_step(x_b, y_b):\n",
    "    # Send x_b and y_b to the GPU, if available\n",
    "    x_b = x_b.to(device)\n",
    "    y_b = y_b.to(device)\n",
    "    # Generate yhat\n",
    "    yhat = model(x_b)\n",
    "    # Calculate the loss\n",
    "    loss = loss_func(yhat, y_b)\n",
    "    # Calculate gradients\n",
    "    loss.backward()\n",
    "    # Perform your update and zero out your gradients\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # Update your accuracy metric\n",
    "    batch_acc = metric(yhat.cpu().softmax(axis=1), y_b.cpu())\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pS45cCPv_gbo"
   },
   "outputs": [],
   "source": [
    "def validation_step(x_b, y_b):\n",
    "    # Send x_b and y_b to the GPU, if available\n",
    "    x_b = x_b.to(device)\n",
    "    y_b = y_b.to(device)\n",
    "    # Tell torch not to calculate gradients on the validation batch\n",
    "    with ...\n",
    "        # Generate yhat\n",
    "        yhat = ...\n",
    "        # Calculate the loss\n",
    "        loss = ...\n",
    "\n",
    "    # Ok, you've seen this before, you do it this time!\n",
    "    batch_acc = ...\n",
    "\n",
    "    # Return the loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "wjt72FF4FrHM"
   },
   "outputs": [],
   "source": [
    "#@markdown Answer: `validation_step`\n",
    "def validation_step(x_b, y_b):\n",
    "    # Send x_b and y_b to the GPU, if available\n",
    "    x_b = x_b.to(device)\n",
    "    y_b = y_b.to(device)\n",
    "    # Tell torch not to calculate gradients on the validation batch\n",
    "    with torch.no_grad():\n",
    "        # Generate yhat\n",
    "        yhat = model(x_b)\n",
    "        # Calculate the loss\n",
    "        loss = loss_func(yhat, y_b)\n",
    "    # Calculate the batch accuracy\n",
    "    batch_acc = metric(yhat.cpu().softmax(axis=1), y_b.cpu())\n",
    "    # Return the loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gsDzYhJ5SpS"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197587,
     "status": "ok",
     "timestamp": 1623902760469,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "KjPF8YoZ5jxr",
    "outputId": "8c37f9c0-6e5d-48e6-f03d-1fdc88f44447"
   },
   "outputs": [],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    # Training loop\n",
    "    model.train() # Put the model in train mode\n",
    "    train_loss_epoch = 0.\n",
    "    for x_b, y_b in train_dl:\n",
    "        loss = train_step(x_b, y_b)\n",
    "        train_loss_epoch += loss\n",
    "    \n",
    "    # Compute the train loss and accuracy for the epoch.\n",
    "    # The epoch loss is a little bit off if our final batch\n",
    "    # is a different size - we're going to ignore that for now,\n",
    "    # since higher-level libraries will solve this for us.\n",
    "    train_loss_epoch /= len(train_dl)\n",
    "    train_acc = metric.compute()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval() # Put themodel in eval mode (affects dropout and batch norm)\n",
    "    val_loss_epoch = 0.\n",
    "    for x_b, y_b in valid_dl:\n",
    "        loss = validation_step(x_b, y_b)\n",
    "        val_loss_epoch += loss\n",
    "    \n",
    "    val_loss_epoch /= len(valid_dl)\n",
    "    valid_acc = metric.compute()\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss_epoch:.04f} Train acc: {float(train_acc):.04f}, Valid loss: {val_loss_epoch} Valid Acc: {float(valid_acc):.04f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Y-goUHmfMAo"
   },
   "outputs": [],
   "source": [
    "def show_preds():\n",
    "    \"\"\"\n",
    "    Shows a actuals and inferences from a random sample of the validation dataset.\n",
    "    \"\"\"\n",
    "    # Sample a few images\n",
    "    sample = mnist_valid_scaled.sample(9)\n",
    "    # Get the sample into a format we can feed into the model\n",
    "    x_b = torch.FloatTensor(sample.loc[:, 1:].values)\n",
    "    y_b = sample.loc[:,0].values\n",
    "\n",
    "    # Make inferences on the sample\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get the inferences, apply softmax to convert to predicted probabilities,\n",
    "        # and use argmax to get the index of the highest probability.\n",
    "        # This is the digit!\n",
    "        preds = model(x_b.to(device)).softmax(dim=-1).argmax(dim=-1).cpu().numpy()\n",
    "    \n",
    "    # Plot a 3x3 grid of digits, where the title\n",
    "    # contains the predictiona nd the actual value.\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    for i, (x, y, p) in enumerate(zip(x_b, y_b, preds)):\n",
    "        ax = fig.add_subplot(3, 3, 1+i)\n",
    "        ax.matshow(x.reshape(28, 28), cmap='Greys_r')\n",
    "        ax.set_title(f'Actual: {y}, Pred: {int(p)}')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    fig.tight_layout()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 876
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1623902760993,
     "user": {
      "displayName": "Mike Frantz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGYCwZXGfGg-CE4_33PQcH9SW8fN6MyRkenN8-IA=s64",
      "userId": "08482506601269125384"
     },
     "user_tz": 420
    },
    "id": "L_f4JkNyC4X7",
    "outputId": "918c637b-1940-4cf8-a29c-32556e225499"
   },
   "outputs": [],
   "source": [
    "show_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiNcOAWLGIbT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "08_Introduction_to_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
