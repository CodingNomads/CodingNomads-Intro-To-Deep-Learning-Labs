{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VSlqSSC-1nAO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "wq_ch3ZZLYmH",
    "outputId": "4e48f216-bc6a-42d9-b0ba-fa76e5b9c0ae"
   },
   "outputs": [],
   "source": [
    "url = 'https://media.istockphoto.com/vectors/chess-silhouettes-vector-id165635822?b=1&k=20&m=165635822&s=612x612&w=0&h=pmf6FVa--nzyWCKb0SyTkIi3xdaHaamJuaR-FIjw1iI='\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content)).convert('L')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KFlFdiI4S7J6"
   },
   "outputs": [],
   "source": [
    "to_tensor = tv.transforms.ToTensor()\n",
    "to_image = tv.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjP50az6Rdnh",
    "outputId": "95d7aba6-c6ef-4bef-9416-849177f3924e"
   },
   "outputs": [],
   "source": [
    "img_tensor = (\n",
    "    to_tensor(img) # Convert to tensor\n",
    "    .unsqueeze(0) # Add a batch dimension\n",
    "    / 255. # Scale between 0 and 1.\n",
    ")\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n7LA-TaGKhp2"
   },
   "outputs": [],
   "source": [
    "vertical_filter = (\n",
    "    torch.tensor([\n",
    "    [1., 0, -1],\n",
    "    [1., 0, -1],\n",
    "    [1., 0, -1],\n",
    "    ]) # This part is the vertical filter\n",
    "    .unsqueeze(0) # Add a dimension for the number of filters (1). In the future, we'll apply more than 1 filter at the same time.\n",
    "    .unsqueeze(0) # Add a dimension for the batch size (1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YI_ss_TqKHZg"
   },
   "outputs": [],
   "source": [
    "vert_output = F.conv2d(img_tensor, vertical_filter).squeeze()\n",
    "vert_image = to_image(vert_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "Xsyg5iTATCV4",
    "outputId": "6672c297-98db-46fa-91ad-c5d83907e9c0"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "axes[0].imshow(img, cmap='Greys_r')\n",
    "axes[0].set_title('Original greyscale image')\n",
    "axes[1].imshow(vert_image, cmap='Greys_r')\n",
    "axes[1].set_title('Feature map of vertical filter')\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anrR11WXu7_L"
   },
   "source": [
    "# Exercise 10.1\n",
    "\n",
    "Use what you learned in this lesson to create a **horizontal** feature map.\n",
    "The result of this exercise should be an edge detector that detects the top edges of the chess pieces and squares on the board.\n",
    "\n",
    "Then, use the `F.conv2d` to apply the filter.\n",
    "\n",
    "<!-- startquestion -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oC51Xvw8wWoD"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "horizontal_filter = ...\n",
    "\n",
    "horizontal_tensor = ...\n",
    "horizontal_image = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2oWAWKCbwej1"
   },
   "outputs": [],
   "source": [
    "assert horizontal_filter.ndim == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "nodTP1FNwA0F",
    "outputId": "a004852e-47c2-4e93-a2c3-5df2d6291ee8"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "axes[0].imshow(img, cmap='Greys_r')\n",
    "axes[0].set_title('Original greyscale image')\n",
    "axes[1].imshow(horizontal_image, cmap='Greys_r')\n",
    "axes[1].set_title('Feature map of horizontal filter')\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LSXV7pvxpiD",
    "outputId": "adb90b28-4787-489b-b305-d70a830079a6"
   },
   "outputs": [],
   "source": [
    "two_filters = torch.cat([vertical_filter, horizontal_filter], dim=0)\n",
    "two_filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfTSAyM9zmEq",
    "outputId": "93d0d147-9c76-4dbc-8b5a-e90863eeb928"
   },
   "outputs": [],
   "source": [
    "two_filter_output = F.conv2d(img_tensor, two_filters)\n",
    "two_filter_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "u-RdZJjrzz4V"
   },
   "outputs": [],
   "source": [
    "# unpack the filters into their own tensors\n",
    "vert_output, horizontal_output = two_filter_output.squeeze()\n",
    "# convert tensors to images\n",
    "vert_image = to_image(vert_output.squeeze())\n",
    "horizontal_image = to_image(horizontal_output.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "GlQMBrYIz7KY",
    "outputId": "af43db62-1ee2-4080-d0e8-28391a035d37"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "axes[0].imshow(vert_image, cmap='Greys_r')\n",
    "axes[0].set_title('Feature map of vertical filter')\n",
    "axes[1].imshow(horizontal_image, cmap='Greys_r')\n",
    "axes[1].set_title('Feature map of horizontal filter')\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SWacj1EV6MhK"
   },
   "outputs": [],
   "source": [
    "zero_pad = nn.ZeroPad2d(30)\n",
    "reflection_pad = nn.ReflectionPad2d(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "oXIHxf7eLmEZ",
    "outputId": "ca14a2d4-064b-489c-a792-416f2760e173"
   },
   "outputs": [],
   "source": [
    "to_image(zero_pad(img_tensor).squeeze() * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "XM-4XLtZ7WzT",
    "outputId": "1e0c5b57-8870-46c1-8ef5-e44909b705e8"
   },
   "outputs": [],
   "source": [
    "to_image(reflection_pad(img_tensor).squeeze() * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "k1rMd1aOO0bm"
   },
   "outputs": [],
   "source": [
    "assert img_tensor.shape == F.conv2d(img_tensor, vertical_filter, padding='same').shape\n",
    "assert img_tensor.shape == F.conv2d(img_tensor, vertical_filter, padding=1).shape\n",
    "assert not img_tensor.shape == F.conv2d(img_tensor, vertical_filter).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNDcsnUDSo8P",
    "outputId": "649a5a5b-c184-4f25-d691-66b6edeca09d"
   },
   "outputs": [],
   "source": [
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebN_qqaRSW5W",
    "outputId": "c8d5a216-bc9f-4091-aa0e-02a1897b1da2"
   },
   "outputs": [],
   "source": [
    "F.conv2d(img_tensor, vertical_filter, padding=1, stride=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5t55mbrSNDM",
    "outputId": "5415474c-cd84-4d15-86e5-d4c5be2ed017"
   },
   "outputs": [],
   "source": [
    "F.conv2d(img_tensor, vertical_filter, padding=1, stride=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "JWEu1x09mkGh",
    "outputId": "7a789839-fa08-40c4-f253-4f803eb10c99"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.syfy.com/sites/syfy/files/styles/scale--1200/public/cast_futurama_bender_0.jpg'\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content)).resize((350, 500))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6j7r7iuPbH8",
    "outputId": "74ce560d-a407-4ae7-ff66-788212ce849a"
   },
   "outputs": [],
   "source": [
    "img_tensor = to_tensor(img).unsqueeze(0)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYr4l75QgWky"
   },
   "source": [
    "# Exercise 10.2\n",
    "\n",
    "Instead of explicitly defining filters, we'll just use random numbers this time.\n",
    "Based on the `F.conv2d` documentation, the filters should be of shape `(out_channels, in_channels, kernel/filter_height, kernel/filter_width)`.\n",
    "\n",
    "Complete the code in the cell below to create a filter with a 3x3 kernel that takes in a 3-channel image and returns a 16-channel feature map.\n",
    "We will use `F.conv2d` to generate the feature map.\n",
    "\n",
    "<!-- startquestion -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEJYUyPwhUdx",
    "outputId": "7eaf1c0c-8665-4575-aa80-d2933f83050c"
   },
   "outputs": [],
   "source": [
    "out_channels = ...\n",
    "in_channels = ...\n",
    "kH = ...\n",
    "kW = ...\n",
    "try:\n",
    "    random_filters = torch.rand((out_channels, in_channels, kH, kW))\n",
    "    print(random_filters.shape)\n",
    "except:\n",
    "    print('Please assign out_channels, in_channels, kH, and kW.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "hvHjxp5giXK7"
   },
   "outputs": [],
   "source": [
    "outputs = F.conv2d(img_tensor, random_filters, padding=1, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "fxI_1T0tPhQQ"
   },
   "outputs": [],
   "source": [
    "assert outputs.shape[1] == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UEOPp8lgQQwq"
   },
   "outputs": [],
   "source": [
    "conv_kwargs = {\n",
    "    'padding': 1,\n",
    "    'stride': 1\n",
    "}\n",
    "\n",
    "conv_layer = nn.Conv2d(3, 16, 3, **conv_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DeR1-mO_2WwO",
    "outputId": "efd3ae2c-c288-4983-972a-80b588965775"
   },
   "outputs": [],
   "source": [
    "conv_layer_output = conv_layer(img_tensor)\n",
    "conv_layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "PRvH0jGyqoW3"
   },
   "outputs": [],
   "source": [
    "conv_function_output = F.conv2d(img_tensor, conv_layer.weight.data, conv_layer.bias.data, **conv_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "v7Q0PmTJqxQP"
   },
   "outputs": [],
   "source": [
    "assert (conv_function_output == conv_layer_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fbOFVavcUxkS"
   },
   "outputs": [],
   "source": [
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R_fH_seVFoC",
    "outputId": "ee3e93dd-7211-401a-9f5f-cd2d3c9f5dcb"
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Oringinal image shape: {img_tensor.shape}\n",
    "Max pool tensor shape: {maxpool(img_tensor).shape}\n",
    "Avg pool tensor shape: {avgpool(img_tensor).shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "krpaM9ufWG89"
   },
   "outputs": [],
   "source": [
    "conv_stride_2 = nn.Conv2d(3, 3, 3, 2, 1)\n",
    "conv_then_pool = nn.Sequential(\n",
    "    nn.Conv2d(3, 3, 3, 1, 1),\n",
    "    nn.MaxPool2d(2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCWGU1JvW4C3",
    "outputId": "26d0b687-3890-4a43-e5ee-6532256db724"
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Shape of conv with a stride of 2: {conv_stride_2(img_tensor).shape}\n",
    "Shape of conv with a poolling layer: {conv_then_pool(img_tensor).shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "uz5vlmPNfS6e"
   },
   "outputs": [],
   "source": [
    "adapt_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "adapt_max_pool = nn.AdaptiveMaxPool2d(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_IEGeE2f7N2",
    "outputId": "d45ff3cd-f177-40fa-a6fe-8726279dfbc7"
   },
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7Owh1gGfXiV",
    "outputId": "102542a5-696a-440a-ea58-aa61feac30b6"
   },
   "outputs": [],
   "source": [
    "adapt_avg_pool(outputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqKoPFFef5By",
    "outputId": "99dfcfb4-64f7-46b0-fb51-ec3542c3f8fd"
   },
   "outputs": [],
   "source": [
    "adapt_pool_with_flatten = nn.Sequential(\n",
    "    nn.AdaptiveMaxPool2d(1),\n",
    "    nn.Flatten()\n",
    ")\n",
    "\n",
    "print(adapt_pool_with_flatten(outputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ON8GY4cjqf65"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQnCpe5l7jTgyPSDMQyZ3s",
   "include_colab_link": true,
   "name": "10_Introduction_to_Convolutional_Neural_Nets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
